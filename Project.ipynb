{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Recommendation by Using LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WSDM - KKBox's Music Recommendation Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final project, we are going to create a music recommendation system. The problem link is [here](https://www.kaggle.com/c/kkbox-music-recommendation-challenge).\n",
    "\n",
    "In this task, we will predict the chances of a user listening to a song repetitively after the first observable listening event within a time window was triggered. If there are recurring listening event(s) triggered within a month after the user’s very first observable listening event, its target is marked 1, and 0 otherwise in the training set. The same rule applies to the testing set.\n",
    "\n",
    "KKBOX provides a training data set consists of information of the first observable listening event for each unique user-song pair within a specific time duration. Metadata of each unique user and song pair is also provided. The use of public data to increase the level of accuracy of your prediction is encouraged.\n",
    "\n",
    "The train and the test data are selected from users listening history in a given time period. Note that this time period is chosen to be before the WSDM-KKBox Churn Prediction time period. The train and test sets are split based on time, and the split of public/private are based on unique user/song pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we adopt boosting machine learning technique.\n",
    "\n",
    "The philosophy of boosting is to use a set of __weak learnners__ to create a __strong learner__. A __weak learner__ is defined to be a classifier which is only slightly correlated with the true classification. In contrast, a __strong learner__ is a classifier that is arbitrarily well-correlated with the true classification.\n",
    "\n",
    "Boosting algorithms consist of iteratively training weak learners with respect to a distribution and adding them to a final strong learner. When the weak learners are added, they are typically weighted with respect to their accuracy. Every time after a weak learner is added, the data are reweighted: __examples that are misclassified gain weight and examples that are classified correctly lose weight__. In this way, future weak learners will focus more on the examples that previous weak learners misclassified. Then by adding new weak learners again and again, finally we will get a strong learner that could handle the task much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light Gradient Boosting Machine (LightGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the weak learner is chosen as (small fixed size) __decision tree__, and differentiable loss functions are adopted, we get a __Gradient Boosting Decision Tree (GBDT)__ [1]. Due to its efficiency, accuracy, and interpretability, GBDT achieves state-of-the-art performances in many machine learning tasks, such as multi-class classification, click prediction, and learning to rank.\n",
    "\n",
    "However, __conventional implementations__ of GBDT need to, for every feature, scan all the data instances to estimate the information gain of all the possible split points. This makes these implementations very time consuming when handling big data. To this end, in 2017 NIPS, Microsoft published a __new implementation__ of GBDT, called __LightGBM__, which speeds up the training process of conventional GBDT by up to over 20 times while achieving almost the same accuracy in experiments on multiple public datasets [1].\n",
    "\n",
    "LightGBM adopted two novel techiques to try to achieve better performance:\n",
    "\n",
    "1. Gradient-based One-Side Sampling (GOSS). According to the definition of information gain, instances with larger gradients (under-trained instances) will contribute more to the information gain. So when down sampling the data instances, one could better keep those instances with large gradients, and only randomly drop those instances with small gradients. It is proved that such a treatment can lead to a more accurate gain estimation than uniformly random sampling, with the same target sampling rate.\n",
    "\n",
    "2. Exclusive Feature Bundling (EFB). In real applications, usually the feature space is quite sparse, many features are (almost) exclusive, i.e., they rarely take nonzero values simultaneously. So it is safely to bundle such exclusive features. To this end, LightGBM includes an efficient algorithm by reducing the optimal bundling problem to a graph coloring problem, and solving it by a greedy algorithm with a constant approximation ratio.\n",
    "\n",
    "With the reduction of size of training data and reduction of number of features, LightGBM is equipped with the ability of faster training speed and higher efficiency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Realization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microsoft made its LightGBM package open source. The package can be found and installed from Github [4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code is based on [here](https://www.kaggle.com/takeshikagawa/calc-roc-area). We make changes to that in following aspects:\n",
    "\n",
    "1. **The original training dataset provided by Kaggle is too large for our slow computers to work on. So does the test dataset. Furthermore, the test data provided by Kaggle does not have labels. This makes us unable to see how the algorithm works. Therefore, we decide to discard the test data. Instead, we extract 10,000 samples from the training data, and split it into a larger group with 7000 samples for training and a smaller group with 3000 samples for testing.**\n",
    "\n",
    "2. **We compared the LightGBM model with random guessing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "ntr = 7000\n",
    "nts = 3000\n",
    "print('Loading data...')\n",
    "data_path = './data/'\n",
    "train = pd.read_csv(data_path + 'train.csv',nrows=ntr)\n",
    "names=['msno','song_id','source_system_tab','source_screen_name',\\\n",
    "      'source_type','target']\n",
    "test1 = pd.read_csv(data_path+'train.csv',names=names,skiprows=ntr,nrows=nts)\n",
    "songs = pd.read_csv(data_path + 'songs.csv')\n",
    "members = pd.read_csv(data_path + 'members.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.csv\n",
    "\n",
    "* msno: user id\n",
    "* song_id: song id\n",
    "* source_system_tab: the name of the tab where the event was triggered. System tabs are used to categorize KKBOX mobile apps functions. For example, tab my library contains functions to manipulate the local storage, and tab search contains functions relating to search.\n",
    "* source_screen_name: name of the layout a user sees.\n",
    "* source_type: an entry point a user first plays music on mobile apps. An entry point could be album, online-playlist, song .. etc.\n",
    "* target: this is the target variable. target=1 means there are recurring listening event(s) triggered within a month after the user’s very first observable listening event, target=0 otherwise ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>song_id</th>\n",
       "      <th>source_system_tab</th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>source_type</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=</td>\n",
       "      <td>BBzumQNXUHKdEBOB7mAJuzok+IJA1c2Ryg/yzTF6tik=</td>\n",
       "      <td>explore</td>\n",
       "      <td>Explore</td>\n",
       "      <td>online-playlist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=</td>\n",
       "      <td>bhp/MpSNoqoxOIB+/l8WPqu6jldth4DIpCm3ayXnJqM=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-playlist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=</td>\n",
       "      <td>JNWfrrC7zNN7BdMpsISKa4Mw+xVJYNnxXh3/Epw7QgY=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-playlist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=</td>\n",
       "      <td>2A87tzfnJTSWqD7gIZHisolhe4DMdzkbd6LzO1KHjNs=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-playlist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=</td>\n",
       "      <td>3qm6XTZ6MOCU11x8FIVbAGH5l5uMkT3/ZalWG1oo2Gc=</td>\n",
       "      <td>explore</td>\n",
       "      <td>Explore</td>\n",
       "      <td>online-playlist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=</td>\n",
       "      <td>3Hg5kugV1S0wzEVLAEfqjIV5UHzb7bCrdBRQlGygLvU=</td>\n",
       "      <td>explore</td>\n",
       "      <td>Explore</td>\n",
       "      <td>online-playlist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  \\\n",
       "0  FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=   \n",
       "1  Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=   \n",
       "2  Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=   \n",
       "3  Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=   \n",
       "4  FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=   \n",
       "5  FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=   \n",
       "\n",
       "                                        song_id source_system_tab  \\\n",
       "0  BBzumQNXUHKdEBOB7mAJuzok+IJA1c2Ryg/yzTF6tik=           explore   \n",
       "1  bhp/MpSNoqoxOIB+/l8WPqu6jldth4DIpCm3ayXnJqM=        my library   \n",
       "2  JNWfrrC7zNN7BdMpsISKa4Mw+xVJYNnxXh3/Epw7QgY=        my library   \n",
       "3  2A87tzfnJTSWqD7gIZHisolhe4DMdzkbd6LzO1KHjNs=        my library   \n",
       "4  3qm6XTZ6MOCU11x8FIVbAGH5l5uMkT3/ZalWG1oo2Gc=           explore   \n",
       "5  3Hg5kugV1S0wzEVLAEfqjIV5UHzb7bCrdBRQlGygLvU=           explore   \n",
       "\n",
       "    source_screen_name      source_type  target  \n",
       "0              Explore  online-playlist       1  \n",
       "1  Local playlist more   local-playlist       1  \n",
       "2  Local playlist more   local-playlist       1  \n",
       "3  Local playlist more   local-playlist       1  \n",
       "4              Explore  online-playlist       1  \n",
       "5              Explore  online-playlist       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### songs.csv\n",
    "\n",
    "The songs. Note that data is in unicode.\n",
    "\n",
    "* song_id\n",
    "* song_length: in ms\n",
    "* genre_ids: genre category. Some songs have multiple genres and they are separated by |\n",
    "* artist_name\n",
    "* composer\n",
    "* lyricist\n",
    "* language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>song_length</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>composer</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXoTN1eb7AI+DntdU1vbcwGRV4SCIDxZu+YD8JP8r4E=</td>\n",
       "      <td>247640</td>\n",
       "      <td>465</td>\n",
       "      <td>張信哲 (Jeff Chang)</td>\n",
       "      <td>董貞</td>\n",
       "      <td>何啟弘</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o0kFgae9QtnYgRkVPqLJwa05zIhRlUjfF7O1tDw0ZDU=</td>\n",
       "      <td>197328</td>\n",
       "      <td>444</td>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>TEDDY|  FUTURE BOUNCE|  Bekuh BOOM</td>\n",
       "      <td>TEDDY</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DwVvVurfpuz+XPuFvucclVQEyPqcpUkHR0ne1RQzPs0=</td>\n",
       "      <td>231781</td>\n",
       "      <td>465</td>\n",
       "      <td>SUPER JUNIOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dKMBWoZyScdxSkihKG+Vf47nc18N9q4m58+b4e7dSSE=</td>\n",
       "      <td>273554</td>\n",
       "      <td>465</td>\n",
       "      <td>S.H.E</td>\n",
       "      <td>湯小康</td>\n",
       "      <td>徐世珍</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W3bqWd3T+VeHFzHAUfARgW9AvVRaF4N5Yzm4Mr6Eo/o=</td>\n",
       "      <td>140329</td>\n",
       "      <td>726</td>\n",
       "      <td>貴族精選</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kKJ2JNU5h8rphyW21ovC+RZU+yEHPM+3w85J37p7vEQ=</td>\n",
       "      <td>235520</td>\n",
       "      <td>864|857|850|843</td>\n",
       "      <td>貴族精選</td>\n",
       "      <td>Joe Hisaishi</td>\n",
       "      <td>Hayao Miyazaki</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        song_id  song_length        genre_ids  \\\n",
       "0  CXoTN1eb7AI+DntdU1vbcwGRV4SCIDxZu+YD8JP8r4E=       247640              465   \n",
       "1  o0kFgae9QtnYgRkVPqLJwa05zIhRlUjfF7O1tDw0ZDU=       197328              444   \n",
       "2  DwVvVurfpuz+XPuFvucclVQEyPqcpUkHR0ne1RQzPs0=       231781              465   \n",
       "3  dKMBWoZyScdxSkihKG+Vf47nc18N9q4m58+b4e7dSSE=       273554              465   \n",
       "4  W3bqWd3T+VeHFzHAUfARgW9AvVRaF4N5Yzm4Mr6Eo/o=       140329              726   \n",
       "5  kKJ2JNU5h8rphyW21ovC+RZU+yEHPM+3w85J37p7vEQ=       235520  864|857|850|843   \n",
       "\n",
       "        artist_name                            composer        lyricist  \\\n",
       "0  張信哲 (Jeff Chang)                                  董貞             何啟弘   \n",
       "1         BLACKPINK  TEDDY|  FUTURE BOUNCE|  Bekuh BOOM           TEDDY   \n",
       "2      SUPER JUNIOR                                 NaN             NaN   \n",
       "3             S.H.E                                 湯小康             徐世珍   \n",
       "4              貴族精選                         Traditional     Traditional   \n",
       "5              貴族精選                        Joe Hisaishi  Hayao Miyazaki   \n",
       "\n",
       "   language  \n",
       "0       3.0  \n",
       "1      31.0  \n",
       "2      31.0  \n",
       "3       3.0  \n",
       "4      52.0  \n",
       "5      17.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### members.csv\n",
    "\n",
    "user information.\n",
    "\n",
    "* msno\n",
    "* city\n",
    "* bd: age. Note: this column has outlier values, please use your judgement.\n",
    "* gender\n",
    "* registered_via: registration method\n",
    "* registration_init_time: format %Y%m%d\n",
    "* expiration_date: format %Y%m%d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>expiration_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XQxgAYj3klVKjR3oxPPXYYFp4soD4TuBghkhMTD4oTw=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20110820</td>\n",
       "      <td>20170920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UizsfmJb9mV54qE9hCYyU07Va97c0lCRLEQX3ae+ztM=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20150628</td>\n",
       "      <td>20170622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D8nEhsIOBSoE6VthTaqDX8U6lqjJ7dLdr72mOyLya2A=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20160411</td>\n",
       "      <td>20170712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mCuD+tZ1hERA/o5GPqk38e041J8ZsBaLcu7nGoIIvhI=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>20150906</td>\n",
       "      <td>20150907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q4HRBfVSssAFS9iRfxWrohxuk9kCYMKjHOEagUMV6rQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20170126</td>\n",
       "      <td>20170613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zgPOEyUn5a/Fvuzb3m69ajzxjkbblVtObglW89FzLdo=</td>\n",
       "      <td>13</td>\n",
       "      <td>43</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>20120703</td>\n",
       "      <td>20171006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  XQxgAYj3klVKjR3oxPPXYYFp4soD4TuBghkhMTD4oTw=     1   0     NaN   \n",
       "1  UizsfmJb9mV54qE9hCYyU07Va97c0lCRLEQX3ae+ztM=     1   0     NaN   \n",
       "2  D8nEhsIOBSoE6VthTaqDX8U6lqjJ7dLdr72mOyLya2A=     1   0     NaN   \n",
       "3  mCuD+tZ1hERA/o5GPqk38e041J8ZsBaLcu7nGoIIvhI=     1   0     NaN   \n",
       "4  q4HRBfVSssAFS9iRfxWrohxuk9kCYMKjHOEagUMV6rQ=     1   0     NaN   \n",
       "5  zgPOEyUn5a/Fvuzb3m69ajzxjkbblVtObglW89FzLdo=    13  43  female   \n",
       "\n",
       "   registered_via  registration_init_time  expiration_date  \n",
       "0               7                20110820         20170920  \n",
       "1               7                20150628         20170622  \n",
       "2               4                20160411         20170712  \n",
       "3               9                20150906         20150907  \n",
       "4               4                20170126         20170613  \n",
       "5               9                20120703         20171006  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have songs.csv, members.csv, train.csv and test1.csv, we want to reduce them into two tables: test and train. We could use left join operation to merge members and songs into train and test data, so that we have more feature columns to train. Besides, we need to remove the null data from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the learned recommendation system in the end, we extract the true labels of test data into ytr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test1.drop(['target'],axis=1)\n",
    "ytr = np.array(test1['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rearrange columns of the test data so that it fits into remain codes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_name = ['id','msno','song_id','source_system_tab',\\\n",
    "             'source_screen_name','source_type']\n",
    "test['id']=np.arange(nts)\n",
    "test = test[test_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract song_cols feilds from songs.csv, then we do a left join with the training and test data, so that we could add more features to the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing...\n"
     ]
    }
   ],
   "source": [
    "print('Data preprocessing...')\n",
    "song_cols = ['song_id', 'artist_name', 'genre_ids', 'song_length', 'language']\n",
    "train = train.merge(songs[song_cols], on='song_id', how='left')\n",
    "test = test.merge(songs[song_cols], on='song_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the members registration time is not semantic, we could split it into three fields: year, month and date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "members['registration_year'] = members['registration_init_time'].apply(lambda x: int(str(x)[0:4]))\n",
    "members['registration_month'] = members['registration_init_time'].apply(lambda x: int(str(x)[4:6]))\n",
    "members['registration_date'] = members['registration_init_time'].apply(lambda x: int(str(x)[6:8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same thing with the expiration date, we also need to drop the original registration time column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "members['expiration_year'] = members['expiration_date'].apply(lambda x: int(str(x)[0:4]))\n",
    "members['expiration_month'] = members['expiration_date'].apply(lambda x: int(str(x)[4:6]))\n",
    "members['expiration_date'] = members['expiration_date'].apply(lambda x: int(str(x)[6:8]))\n",
    "members = members.drop(['registration_init_time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after we processed the members table, we do a left join again with the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "members_cols = members.columns\n",
    "train = train.merge(members[members_cols], on='msno', how='left')\n",
    "test = test.merge(members[members_cols], on='msno', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For null data in the train and test data, we fill them as -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do some garbage collection work for members and songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "del members, songs; gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = list(train.columns)\n",
    "cols.remove('target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the current train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>song_id</th>\n",
       "      <th>source_system_tab</th>\n",
       "      <th>source_screen_name</th>\n",
       "      <th>source_type</th>\n",
       "      <th>target</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>song_length</th>\n",
       "      <th>language</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>expiration_date</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>registration_date</th>\n",
       "      <th>expiration_year</th>\n",
       "      <th>expiration_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=</td>\n",
       "      <td>BBzumQNXUHKdEBOB7mAJuzok+IJA1c2Ryg/yzTF6tik=</td>\n",
       "      <td>explore</td>\n",
       "      <td>Explore</td>\n",
       "      <td>online-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>Bastille</td>\n",
       "      <td>359</td>\n",
       "      <td>206471</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=</td>\n",
       "      <td>bhp/MpSNoqoxOIB+/l8WPqu6jldth4DIpCm3ayXnJqM=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>Various Artists</td>\n",
       "      <td>1259</td>\n",
       "      <td>284584</td>\n",
       "      <td>52.0</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=</td>\n",
       "      <td>JNWfrrC7zNN7BdMpsISKa4Mw+xVJYNnxXh3/Epw7QgY=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>Nas</td>\n",
       "      <td>1259</td>\n",
       "      <td>225396</td>\n",
       "      <td>52.0</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=</td>\n",
       "      <td>2A87tzfnJTSWqD7gIZHisolhe4DMdzkbd6LzO1KHjNs=</td>\n",
       "      <td>my library</td>\n",
       "      <td>Local playlist more</td>\n",
       "      <td>local-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>Soundway</td>\n",
       "      <td>1019</td>\n",
       "      <td>255512</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=</td>\n",
       "      <td>3qm6XTZ6MOCU11x8FIVbAGH5l5uMkT3/ZalWG1oo2Gc=</td>\n",
       "      <td>explore</td>\n",
       "      <td>Explore</td>\n",
       "      <td>online-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>Brett Young</td>\n",
       "      <td>1011</td>\n",
       "      <td>187802</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=</td>\n",
       "      <td>3Hg5kugV1S0wzEVLAEfqjIV5UHzb7bCrdBRQlGygLvU=</td>\n",
       "      <td>explore</td>\n",
       "      <td>Explore</td>\n",
       "      <td>online-playlist</td>\n",
       "      <td>1</td>\n",
       "      <td>Desiigner</td>\n",
       "      <td>1259</td>\n",
       "      <td>247803</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  \\\n",
       "0  FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=   \n",
       "1  Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=   \n",
       "2  Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=   \n",
       "3  Xumu+NIjS6QYVxDS4/t3SawvJ7viT9hPKXmf0RtLNx8=   \n",
       "4  FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=   \n",
       "5  FGtllVqz18RPiwJj/edr2gV78zirAiY/9SmYvia+kCg=   \n",
       "\n",
       "                                        song_id source_system_tab  \\\n",
       "0  BBzumQNXUHKdEBOB7mAJuzok+IJA1c2Ryg/yzTF6tik=           explore   \n",
       "1  bhp/MpSNoqoxOIB+/l8WPqu6jldth4DIpCm3ayXnJqM=        my library   \n",
       "2  JNWfrrC7zNN7BdMpsISKa4Mw+xVJYNnxXh3/Epw7QgY=        my library   \n",
       "3  2A87tzfnJTSWqD7gIZHisolhe4DMdzkbd6LzO1KHjNs=        my library   \n",
       "4  3qm6XTZ6MOCU11x8FIVbAGH5l5uMkT3/ZalWG1oo2Gc=           explore   \n",
       "5  3Hg5kugV1S0wzEVLAEfqjIV5UHzb7bCrdBRQlGygLvU=           explore   \n",
       "\n",
       "    source_screen_name      source_type  target      artist_name genre_ids  \\\n",
       "0              Explore  online-playlist       1         Bastille       359   \n",
       "1  Local playlist more   local-playlist       1  Various Artists      1259   \n",
       "2  Local playlist more   local-playlist       1              Nas      1259   \n",
       "3  Local playlist more   local-playlist       1         Soundway      1019   \n",
       "4              Explore  online-playlist       1      Brett Young      1011   \n",
       "5              Explore  online-playlist       1        Desiigner      1259   \n",
       "\n",
       "   song_length  language  city  bd  gender  registered_via  expiration_date  \\\n",
       "0       206471      52.0     1   0      -1               7                5   \n",
       "1       284584      52.0    13  24  female               9               11   \n",
       "2       225396      52.0    13  24  female               9               11   \n",
       "3       255512      -1.0    13  24  female               9               11   \n",
       "4       187802      52.0     1   0      -1               7                5   \n",
       "5       247803      52.0     1   0      -1               7                5   \n",
       "\n",
       "   registration_year  registration_month  registration_date  expiration_year  \\\n",
       "0               2012                   1                  2             2017   \n",
       "1               2011                   5                 25             2017   \n",
       "2               2011                   5                 25             2017   \n",
       "3               2011                   5                 25             2017   \n",
       "4               2012                   1                  2             2017   \n",
       "5               2012                   1                  2             2017   \n",
       "\n",
       "   expiration_month  \n",
       "0                10  \n",
       "1                 9  \n",
       "2                 9  \n",
       "3                 9  \n",
       "4                10  \n",
       "5                10  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we will use LabelEncoder in sklearn to precess with the string data in train and test. We firstly get the total number of kinds in both train and test, then we use labelEncoder to put each kind a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 19/19 [00:00<00:00, 50.36it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(cols):\n",
    "    if train[col].dtype == 'object':\n",
    "        train[col] = train[col].apply(str)\n",
    "        test[col] = test[col].apply(str)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        train_vals = list(train[col].unique())\n",
    "        test_vals = list(test[col].unique())\n",
    "        le.fit(train_vals + test_vals)\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the populartiy of the songs from the songs.csv and add it to the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Song popularity\n",
    "unique_songs = range(max(train['song_id'].max(), test['song_id'].max()))\n",
    "song_popularity = pd.DataFrame({'song_id': unique_songs, 'popularity':0})\n",
    "\n",
    "train_sorted = train.sort_values('song_id')\n",
    "train_sorted.reset_index(drop=True, inplace=True)\n",
    "test_sorted = test.sort_values('song_id')\n",
    "test_sorted.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5770/5770 [00:26<00:00, 218.65it/s]\n"
     ]
    }
   ],
   "source": [
    "for unique_song in tqdm(unique_songs):\n",
    "    if unique_song != (len(unique_songs)-1):\n",
    "        train_pop = (train_sorted['song_id'].searchsorted(unique_song+1)[0] - \n",
    "                     train_sorted['song_id'].searchsorted(unique_song)[0])\n",
    "        test_pop = (test_sorted['song_id'].searchsorted(unique_song+1)[0] - \n",
    "                     test_sorted['song_id'].searchsorted(unique_song)[0])\n",
    "    else : \n",
    "        train_pop = (len(train_sorted) -\n",
    "                     train_sorted['song_id'].searchsorted(unique_song)[0])\n",
    "        test_pop = (len(test_sorted) -\n",
    "                     test_sorted['song_id'].searchsorted(unique_song)[0])\n",
    "    song_popularity[unique_song] = train_pop + test_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to train the model, note that we firstly split the training data into 90% training data and 10% validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User library size\n",
    "X = np.array(train.drop(['target'], axis=1))\n",
    "y = train['target'].values\n",
    "\n",
    "X_test = np.array(test.drop(['id'], axis=1))\n",
    "ids = test['id'].values\n",
    "\n",
    "del train, test; gc.collect();\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \\\n",
    "    test_size=0.1, random_state = 12)\n",
    "    \n",
    "del X, y; gc.collect();\n",
    "\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "d_valid = lgb.Dataset(X_valid, label=y_valid) \n",
    "\n",
    "watchlist = [d_train, d_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to train the model, we first create a parameter dict, set the learning rate to 0.4, and we make it print out the acurracy during the calculation. We also set the valid_sets to watchlist to validate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LGBM model...\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[10]\ttraining's auc: 0.990018\tvalid_1's auc: 0.844558\n",
      "[20]\ttraining's auc: 0.999901\tvalid_1's auc: 0.839645\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's auc: 0.997805\tvalid_1's auc: 0.849754\n"
     ]
    }
   ],
   "source": [
    "print('Training LGBM model...')\n",
    "params = {}\n",
    "params['learning_rate'] = 0.4\n",
    "params['application'] = 'binary'\n",
    "params['max_depth'] = 15\n",
    "params['num_leaves'] = 2**8\n",
    "params['verbosity'] = 0\n",
    "params['metric'] = 'auc'\n",
    "\n",
    "model = lgb.train(params, train_set=d_train, num_boost_round=200, valid_sets=watchlist, \\\n",
    "early_stopping_rounds=10, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions and saving them...\n"
     ]
    }
   ],
   "source": [
    "print('Making predictions and saving them...')\n",
    "p_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "subm = pd.DataFrame()\n",
    "subm['id'] = ids\n",
    "subm['target'] = p_test\n",
    "subm.to_csv('submission.csv.gz', compression = 'gzip', index=False, float_format = '%.5f')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each id in the test data, the model predicted the probablity that the user will listen to the corresponding song for the second time in the future. The result is stored in p_test. Now We use a hard thredhold rule to obtain yhat. That is, if $p_{test}[i]>0.5$, $yhat=1$, else $yhat=0$. Then we can calculate the accuracy acc of our lgbm model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of lgbm model on test data is: 77.900000%\n"
     ]
    }
   ],
   "source": [
    "yhat = (p_test>0.5).astype(int)\n",
    "comp = (yhat==ytr).astype(int)\n",
    "acc = comp.sum()/comp.size*100\n",
    "print('The accuracy of lgbm model on test data is: {0:f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a comparison, we use a random guessing to predict on the same test data set. That is, to assign yhat_rand 1 or 2 for each id in test data according to $Bernoulli(1/2)$ distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of random model on test data is: 50.033333%\n"
     ]
    }
   ],
   "source": [
    "rd_seed = np.random.uniform(0,1,nts)\n",
    "yhat_rand = (rd_seed>0.5).astype(int)\n",
    "comp_rand = (yhat_rand==ytr).astype(int)\n",
    "acc_rand = comp_rand.sum()/comp_rand.size*100\n",
    "print('The accuracy of random model on test data is: {0:f}%'.format(acc_rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, lgbm model is better than random guessing. This means that the chosen lgbm model indeed improved the predicition accuracy on this problem. Of course, it is just a first trial, there are much work to do if one wants to further enhance the prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Friedman J H. Greedy function approximation: a gradient boosting machine[J]. Annals of statistics, 2001: 1189-1232."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] Ke G, Meng Q, Wang T, et al. A Highly Efficient Gradient Boosting Decision Tree[C]//Advances in Neural Information Processing Systems. 2017: 3148-3156."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] https://www.kaggle.com/c/kkbox-music-recommendation-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] https://github.com/Microsoft/LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
